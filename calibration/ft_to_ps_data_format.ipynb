{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HMves1I9V8Pa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "from scipy.spatial import KDTree\n",
        "from typing import Dict, List, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# CONFIGURATION AND PATH SETUP\n",
        "# ==============================================================================\n",
        "\n",
        "# Define global paths using relative directory\n",
        "# Assuming this script is run from the root directory containing the data subfolders.\n",
        "data_folder_dp = '.' \n",
        "\n",
        "# Base folder where all ALIGNED data subfolders will be created\n",
        "# This folder will be created inside the current working directory.\n",
        "output_base_dp = os.path.join(data_folder_dp, 'Aligned_FT_Data')\n",
        "os.makedirs(output_base_dp, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "K-BazMqsTnjO",
        "outputId": "15839650-b520-4f23-c364-3fd7df8d6259"
      },
      "outputs": [],
      "source": [
        "def find_step_time(times, values, threshold, window_size):\n",
        "    \"\"\"Find the first time where values change significantly (used for synchronization).\"\"\"\n",
        "    starting_i = 0\n",
        "    for i in range(len(values) - window_size):\n",
        "        if abs(values[i + window_size] - values[i]) > threshold:\n",
        "            starting_i = i\n",
        "            break\n",
        "    \n",
        "    max_diff_idx = starting_i\n",
        "    max_diff = 0\n",
        "    for j in range(starting_i, min(starting_i + window_size + 1, len(values))):\n",
        "        diff = abs(values[j] - values[starting_i])\n",
        "        if diff > max_diff:\n",
        "            max_diff = diff\n",
        "            max_diff_idx = j\n",
        "            \n",
        "    return times[max_diff_idx] if max_diff_idx < len(times) else None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QuNJqv9DosiR"
      },
      "outputs": [],
      "source": [
        "def check_and_group_file_pairs(files: List[str]) -> Tuple[Dict[str, List[str]], List[str]]:\n",
        "    \"\"\"Groups files by suffix to find matching 'ft' and 'ps' pairs.\"\"\"\n",
        "    grouped_files = defaultdict(lambda: defaultdict(list))\n",
        "    matching_pairs = {}\n",
        "    unmatched_files = []\n",
        "    \n",
        "    for filename in files:\n",
        "        if len(filename) > 2:\n",
        "            prefix = filename[:2].lower()\n",
        "            suffix = filename[2:] \n",
        "            if prefix in ['ft', 'ps']:\n",
        "                grouped_files[suffix][prefix].append(filename)\n",
        "\n",
        "    for suffix, prefixes in grouped_files.items():\n",
        "        if 'ft' in prefixes and 'ps' in prefixes:\n",
        "            matches = prefixes['ft'] + prefixes['ps']\n",
        "            matching_pairs[suffix] = matches\n",
        "        else:\n",
        "            if 'ft' in prefixes and len(prefixes['ft']) > 0:\n",
        "                unmatched_files.extend(prefixes['ft'])\n",
        "            if 'ps' in prefixes and len(prefixes['ps']) > 0:\n",
        "                unmatched_files.extend(prefixes['ps'])\n",
        "    \n",
        "    return matching_pairs, unmatched_files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wAb1wlUCpEdh"
      },
      "outputs": [],
      "source": [
        "def process_and_synchronize_pair_flexible(ft_full_path, psoc_full_path, output_path):\n",
        "    \"\"\"\n",
        "    Loads, processes, synchronizes, and saves aligned FT and PSOC sensor data.\n",
        "    Takes full file paths and saves output to the specified output_path.\n",
        "    \"\"\"\n",
        "    ft_filename = os.path.basename(ft_full_path)\n",
        "    psoc_filename = os.path.basename(psoc_full_path)\n",
        "\n",
        "    # --- 1. Load Data ---\n",
        "    try:\n",
        "        ft_sensor_data_orig = pd.read_csv(ft_full_path)\n",
        "        psoc_data_orig = pd.read_csv(psoc_full_path)\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR loading files {ft_filename} and {psoc_filename}: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    psoc_data = psoc_data_orig.copy()\n",
        "    ft_sensor_data = ft_sensor_data_orig.copy()\n",
        "    \n",
        "    # Determine output file name:\n",
        "    suffix = psoc_filename.lower().replace('ps_', '').replace('.csv', '')\n",
        "    output_filename = f\"ft_ALIGNED_{suffix}.csv\"\n",
        "    output_filepath = os.path.join(output_path, output_filename)\n",
        "\n",
        "    print(f\"\\n--- Processing Pair: {ft_filename} / {psoc_filename} ---\")\n",
        "\n",
        "    # --- 2. PSOC Data Transformation (Timestamp Fix & Matrix Creation) ---\n",
        "    col0 = psoc_data.columns[0]\n",
        "    psoc_data[col0] = pd.to_numeric(psoc_data[col0], errors='coerce')\n",
        "    psoc_data.loc[psoc_data[col0] < 0, col0] += 10000\n",
        "    psoc_data[col0] = psoc_data[col0].cumsum() / 10000\n",
        "\n",
        "    n = len(psoc_data)\n",
        "    psoc_matrix = np.full((n, 17), np.nan, dtype=float)\n",
        "    psoc_matrix[:, 0] = psoc_data[col0].values\n",
        "    \n",
        "    mode_col, pin_col, val_col = psoc_data.columns[1], psoc_data.columns[2], psoc_data.columns[3]\n",
        "    modes = pd.to_numeric(psoc_data[mode_col], errors='coerce').to_numpy(dtype=float)\n",
        "    pins = pd.to_numeric(psoc_data[pin_col], errors='coerce').to_numpy(dtype=float)\n",
        "    vals = pd.to_numeric(psoc_data[val_col], errors='coerce').to_numpy(dtype=float)\n",
        "\n",
        "    indices = 8 * modes + pins\n",
        "    valid = np.isfinite(indices) & (indices >= 0) & (indices < 16) & np.isfinite(vals)\n",
        "    rows = np.nonzero(valid)[0]\n",
        "    cols = indices[valid].astype(int) + 1\n",
        "    psoc_matrix[rows, cols] = vals[valid]\n",
        "    \n",
        "    col_names = ['timestamp'] + [f'ch{i}' for i in range(1, 17)]\n",
        "    df_psoc = pd.DataFrame(psoc_matrix, columns=col_names)\n",
        "\n",
        "    # --- 3. Interpolation & Biasing ---\n",
        "    sensor_cols = col_names[1:]\n",
        "    df_psoc[sensor_cols] = df_psoc[sensor_cols].replace(0.0, np.nan)\n",
        "    df_psoc.interpolate(method='linear', axis=0, limit_area='inside', inplace=True)\n",
        "    df_psoc.fillna(0.0, inplace=True)\n",
        "\n",
        "    for col in sensor_cols:\n",
        "        col_ser = df_psoc[col]\n",
        "        nonzero_mask = col_ser.notna() & (col_ser != 0)\n",
        "        if nonzero_mask.any():\n",
        "            first_val = col_ser.loc[nonzero_mask].iloc[0]\n",
        "            finite_mask = col_ser.notna()\n",
        "            df_psoc.loc[finite_mask, col] = df_psoc.loc[finite_mask, col] - first_val\n",
        "\n",
        "    df_psoc = df_psoc.iloc[16:-16].reset_index(drop=True)\n",
        "    psoc_data = df_psoc.copy()\n",
        "\n",
        "    # --- 4. Relative Timestamp Normalization ---\n",
        "    ft_start_time = ft_sensor_data['timestamp'].iloc[0]\n",
        "    psoc_start_time = psoc_data['timestamp'].iloc[0]\n",
        "    ft_sensor_data['timestamp'] = ft_sensor_data['timestamp'] - ft_start_time\n",
        "    psoc_data['timestamp'] = (psoc_data['timestamp'] - psoc_start_time)\n",
        "    \n",
        "    # --- 5. Synchronization Logic ---\n",
        "    ft_copy, psoc_copy = ft_sensor_data.copy(), psoc_data.copy()\n",
        "    ft_mean = ft_copy.drop(columns=['timestamp']).mean(axis=1).to_numpy()\n",
        "    psoc_mean = psoc_copy.drop(columns=['timestamp']).mean(axis=1).to_numpy()\n",
        "    \n",
        "    # Guard against division by zero if all values are identical\n",
        "    if ft_mean.max() != ft_mean.min():\n",
        "        ft_mean = (ft_mean - ft_mean.min()) / (ft_mean.max() - ft_mean.min())\n",
        "    if psoc_mean.max() != psoc_mean.min():\n",
        "        psoc_mean = (psoc_mean - psoc_mean.min()) / (psoc_mean.max() - psoc_mean.min())\n",
        "\n",
        "    ft_times = ft_copy['timestamp'].to_numpy()\n",
        "    psoc_times = psoc_copy['timestamp'].to_numpy()\n",
        "\n",
        "    ft_change_time = find_step_time(ft_times, ft_mean, threshold=0.0075, window_size=500)\n",
        "    psoc_change_time = find_step_time(psoc_times, psoc_mean, threshold=0.05, window_size=500)\n",
        "\n",
        "    if ft_change_time is None or psoc_change_time is None:\n",
        "        offset_time = 0.0\n",
        "        print(\"WARNING: Step time could not be found in one or both files. Applying zero offset.\")\n",
        "    else:\n",
        "        offset_time = ft_change_time - psoc_change_time\n",
        "        print(f\"FT Change: {ft_change_time:.4f} s, PSOC Change: {psoc_change_time:.4f} s\")\n",
        "    \n",
        "    psoc_data['timestamp'] = (psoc_data['timestamp'] + offset_time)\n",
        "\n",
        "    # --- 6. Alignment (Nearest Neighbor Mapping) ---\n",
        "    ft_timestamps = ft_sensor_data['timestamp'].values.reshape(-1, 1)\n",
        "    psoc_timestamps = psoc_data['timestamp'].values.reshape(-1, 1)\n",
        "    tree = KDTree(ft_timestamps)\n",
        "    distances, indices = tree.query(psoc_timestamps)\n",
        "\n",
        "    X = psoc_data.drop('timestamp', axis=1).values\n",
        "    ft_output_cols = ['fx', 'fy', 'fz', 'tx', 'ty', 'tz']\n",
        "    y = ft_sensor_data.iloc[indices][ft_output_cols].values\n",
        "\n",
        "    aligned_data = pd.DataFrame(X, columns=psoc_data.drop('timestamp', axis=1).columns)\n",
        "    aligned_data[ft_output_cols] = y\n",
        "    aligned_data['timestamp'] = psoc_data['timestamp'].values\n",
        "    \n",
        "    print(f\"Alignment complete: {aligned_data.shape[0]} samples. Avg time diff: {distances.mean()*1000:.3f} ms\")\n",
        "\n",
        "    # --- 7. Save Aligned Data ---\n",
        "    selected_columns = ['timestamp'] + ft_output_cols + [col for col in aligned_data.columns if col not in ['timestamp'] + ft_output_cols]\n",
        "    aligned_data_filtered = aligned_data[selected_columns]\n",
        "    \n",
        "    aligned_data_filtered.to_csv(output_filepath, index=False)\n",
        "    print(f\"Data saved to: {output_filepath}\")\n",
        "    \n",
        "    return aligned_data_filtered, output_filepath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_files_and_counts(target_folder_path: str) -> Tuple[List[str], Dict[str, int]]:\n",
        "    \"\"\"\n",
        "    Lists all files in the specified folder and counts files\n",
        "    starting with 'ft_' and 'ps_'. This function is non-recursive.\n",
        "\n",
        "    Args:\n",
        "        target_folder_path: The full path of the directory to analyze.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing:\n",
        "        1. A list of all filenames found (not full paths).\n",
        "        2. A dictionary of counts {'total': int, 'ft_count': int, 'ps_count': int}.\n",
        "    \"\"\"\n",
        "    # Use the full path directly\n",
        "    if not os.path.isdir(target_folder_path):\n",
        "        print(f\"Error: Directory not found at {target_folder_path}\")\n",
        "        return [], {'total': 0, 'ft_count': 0, 'ps_count': 0}\n",
        "\n",
        "    contents = os.listdir(target_folder_path)\n",
        "    # Filter out directories and count only files\n",
        "    files = [f for f in contents if os.path.isfile(os.path.join(target_folder_path, f))]\n",
        "\n",
        "    ft_count = 0\n",
        "    ps_count = 0\n",
        "\n",
        "    for filename in files:\n",
        "        filename_lower = filename.lower()\n",
        "        if filename_lower.startswith('ft_'):\n",
        "            ft_count += 1\n",
        "        if filename_lower.startswith('ps_'):\n",
        "            ps_count += 1\n",
        "\n",
        "    print(f\"--- File Count Utility Result ---\")\n",
        "    print(f\"Directory: {target_folder_path}\")\n",
        "    print(f\"Total files found: {len(files)}\")\n",
        "    print(f\"Files starting with 'ft_': {ft_count}\")\n",
        "    print(f\"Files starting with 'ps_': {ps_count}\")\n",
        "    print(f\"---------------------------------\")\n",
        "\n",
        "\n",
        "    return files, {'total': len(files), 'ft_count': ft_count, 'ps_count': ps_count}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FA4_TUIFtRGi"
      },
      "source": [
        "# **Generate aligned CSVs for all AHG FT data in the same table format as our FT data**  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "######################################################################\n",
            "## Starting Recursive Data Alignment with Dynamic Folders \n",
            "######################################################################\n",
            "Input Base (Current Directory): c:\\Users\\sneaz\\OneDrive\\Desktop\\UT\\2025-2026\\ECE382N_TACTILE\\Data Processing\n",
            "Output Base: c:\\Users\\sneaz\\OneDrive\\Desktop\\UT\\2025-2026\\ECE382N_TACTILE\\Data Processing\\Aligned_FT_Data\n",
            "Found 2 files in: Eco10_ALIGNED/\n",
            "Found 2 files in: EcoSugar2mm_ALIGNED/\n",
            "Found 15 files in: Eco_ALIGNED/\n",
            "Found 14 files in: Poly_ALIGNED/\n",
            "Found 1 files in: Missing_/\n",
            "Found 4 files in: Eco/\n",
            "Found 4 files in: Poly/\n",
            "Found 4 files in: Eco/\n",
            "Found 4 files in: Poly/\n",
            "Found 4 files in: Eco/\n",
            "Found 4 files in: EcoSugar2mm/\n",
            "Found 6 files in: Poly/\n",
            "Found 6 files in: Eco/\n",
            "Found 4 files in: Poly/\n",
            "Found 4 files in: Eco/\n",
            "Found 4 files in: Eco10/\n",
            "Found 4 files in: Poly/\n",
            "Found 4 files in: Eco/\n",
            "Found 4 files in: Poly/\n",
            "Found 4 files in: Eco/\n",
            "Found 4 files in: Poly/\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: Eco10_ALIGNED/\n",
            "Saving to OUTPUT: Eco10_ALIGNED_ALIGNED/\n",
            "==================================================================\n",
            "No matching FT/PS pairs found in Eco10_ALIGNED. Skipping to next folder.\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: EcoSugar2mm_ALIGNED/\n",
            "Saving to OUTPUT: EcoSugar2mm_ALIGNED_ALIGNED/\n",
            "==================================================================\n",
            "No matching FT/PS pairs found in EcoSugar2mm_ALIGNED. Skipping to next folder.\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: Eco_ALIGNED/\n",
            "Saving to OUTPUT: Eco_ALIGNED_ALIGNED/\n",
            "==================================================================\n",
            "No matching FT/PS pairs found in Eco_ALIGNED. Skipping to next folder.\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: Poly_ALIGNED/\n",
            "Saving to OUTPUT: Poly_ALIGNED_ALIGNED/\n",
            "==================================================================\n",
            "No matching FT/PS pairs found in Poly_ALIGNED. Skipping to next folder.\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: Missing_/\n",
            "Saving to OUTPUT: Missing__ALIGNED/\n",
            "==================================================================\n",
            "No matching FT/PS pairs found in Missing_. Skipping to next folder.\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: Eco/\n",
            "Saving to OUTPUT: Eco_ALIGNED/\n",
            "==================================================================\n",
            "\n",
            "--- Processing Pair: ft_new_blue_ecoflex_1.csv / ps_new_blue_ecoflex_1.csv ---\n",
            "FT Change: 2.5850 s, PSOC Change: 3.1919 s\n",
            "Alignment complete: 22286 samples. Avg time diff: 5.490 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Eco_ALIGNED\\ft_ALIGNED_new_blue_ecoflex_1.csv\n",
            "\n",
            "--- Processing Pair: ft_new_blue_ecoflex_random.csv / ps_new_blue_ecoflex_random.csv ---\n",
            "FT Change: 1.4145 s, PSOC Change: 2.0218 s\n",
            "Alignment complete: 22284 samples. Avg time diff: 4.311 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Eco_ALIGNED\\ft_ALIGNED_new_blue_ecoflex_random.csv\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: Poly/\n",
            "Saving to OUTPUT: Poly_ALIGNED/\n",
            "==================================================================\n",
            "\n",
            "--- Processing Pair: ft_new_blue_poly_1.csv / ps_new_blue_poly_1.csv ---\n",
            "FT Change: 1.9694 s, PSOC Change: 1.9865 s\n",
            "Alignment complete: 22326 samples. Avg time diff: 2.281 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Poly_ALIGNED\\ft_ALIGNED_new_blue_poly_1.csv\n",
            "\n",
            "--- Processing Pair: ft_new_blue_poly_random.csv / ps_new_blue_poly_random.csv ---\n",
            "FT Change: 0.9699 s, PSOC Change: 1.9836 s\n",
            "Alignment complete: 22336 samples. Avg time diff: 7.928 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Poly_ALIGNED\\ft_ALIGNED_new_blue_poly_random.csv\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: Eco/\n",
            "Saving to OUTPUT: Eco_ALIGNED/\n",
            "==================================================================\n",
            "\n",
            "--- Processing Pair: ft_new_purple_ecoflex_1.csv / ps_new_purple_ecoflex_1.csv ---\n",
            "FT Change: 2.6590 s, PSOC Change: 5.2976 s\n",
            "Alignment complete: 22290 samples. Avg time diff: 40.812 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Eco_ALIGNED\\ft_ALIGNED_new_purple_ecoflex_1.csv\n",
            "\n",
            "--- Processing Pair: ft_new_purple_ecoflex_random.csv / ps_new_purple_ecoflex_random.csv ---\n",
            "FT Change: 1.3246 s, PSOC Change: 4.5416 s\n",
            "Alignment complete: 22296 samples. Avg time diff: 59.640 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Eco_ALIGNED\\ft_ALIGNED_new_purple_ecoflex_random.csv\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: Poly/\n",
            "Saving to OUTPUT: Poly_ALIGNED/\n",
            "==================================================================\n",
            "\n",
            "--- Processing Pair: ft_new_purple_poly_1.csv / ps_new_purple_poly_1.csv ---\n",
            "FT Change: 5.9441 s, PSOC Change: 4.9726 s\n",
            "Alignment complete: 22283 samples. Avg time diff: 2.258 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Poly_ALIGNED\\ft_ALIGNED_new_purple_poly_1.csv\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: Eco/\n",
            "Saving to OUTPUT: Eco_ALIGNED/\n",
            "==================================================================\n",
            "\n",
            "--- Processing Pair: ft_new_white_ecoflex_w_1.csv / ps_new_white_ecoflex_w_1.csv ---\n",
            "FT Change: 5.6052 s, PSOC Change: 5.0021 s\n",
            "Alignment complete: 22256 samples. Avg time diff: 2.161 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Eco_ALIGNED\\ft_ALIGNED_new_white_ecoflex_w_1.csv\n",
            "\n",
            "--- Processing Pair: ft_new_white_ecoflex_w_random.csv / ps_new_white_ecoflex_w_random.csv ---\n",
            "FT Change: 4.2221 s, PSOC Change: 4.0056 s\n",
            "Alignment complete: 22224 samples. Avg time diff: 2.280 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Eco_ALIGNED\\ft_ALIGNED_new_white_ecoflex_w_random.csv\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: EcoSugar2mm/\n",
            "Saving to OUTPUT: EcoSugar2mm_ALIGNED/\n",
            "==================================================================\n",
            "\n",
            "--- Processing Pair: ft_new_white_ecoflex_sugar_2mm_1.csv / ps_new_white_ecoflex_sugar_2mm_1.csv ---\n",
            "FT Change: 7.9004 s, PSOC Change: 6.4125 s\n",
            "Alignment complete: 22309 samples. Avg time diff: 2.277 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\EcoSugar2mm_ALIGNED\\ft_ALIGNED_new_white_ecoflex_sugar_2mm_1.csv\n",
            "\n",
            "--- Processing Pair: ft_new_white_ecoflex_sugar_2mm_random.csv / ps_new_white_ecoflex_sugar_2mm_random.csv ---\n",
            "FT Change: 3.9305 s, PSOC Change: 3.5616 s\n",
            "Alignment complete: 22306 samples. Avg time diff: 2.219 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\EcoSugar2mm_ALIGNED\\ft_ALIGNED_new_white_ecoflex_sugar_2mm_random.csv\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: Poly/\n",
            "Saving to OUTPUT: Poly_ALIGNED/\n",
            "==================================================================\n",
            "\n",
            "--- Processing Pair: ft_new_white_poly_1.csv / ps_new_white_poly_1.csv ---\n",
            "FT Change: 5.8176 s, PSOC Change: 19.8671 s\n",
            "Alignment complete: 25727 samples. Avg time diff: 951.158 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Poly_ALIGNED\\ft_ALIGNED_new_white_poly_1.csv\n",
            "\n",
            "--- Processing Pair: ft_new_white_poly_2.csv / ps_new_white_poly_2.csv ---\n",
            "FT Change: 5.5576 s, PSOC Change: 16.8340 s\n",
            "Alignment complete: 25079 samples. Avg time diff: 628.030 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Poly_ALIGNED\\ft_ALIGNED_new_white_poly_2.csv\n",
            "\n",
            "--- Processing Pair: ft_new_white_poly_random.csv / ps_new_white_poly_random.csv ---\n",
            "FT Change: 5.3057 s, PSOC Change: 17.8759 s\n",
            "Alignment complete: 25232 samples. Avg time diff: 775.119 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Poly_ALIGNED\\ft_ALIGNED_new_white_poly_random.csv\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: Eco/\n",
            "Saving to OUTPUT: Eco_ALIGNED/\n",
            "==================================================================\n",
            "\n",
            "--- Processing Pair: ft_new_yellow_ecoflex_1.csv / ps_new_yellow_ecoflex_1.csv ---\n",
            "FT Change: 3.7183 s, PSOC Change: 5.3220 s\n",
            "Alignment complete: 22332 samples. Avg time diff: 16.417 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Eco_ALIGNED\\ft_ALIGNED_new_yellow_ecoflex_1.csv\n",
            "\n",
            "--- Processing Pair: ft_new_yellow_ecoflex_2.csv / ps_new_yellow_ecoflex_2.csv ---\n",
            "FT Change: 1.7997 s, PSOC Change: 2.4948 s\n",
            "Alignment complete: 22327 samples. Avg time diff: 4.913 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Eco_ALIGNED\\ft_ALIGNED_new_yellow_ecoflex_2.csv\n",
            "\n",
            "--- Processing Pair: ft_new_yellow_ecoflex_random_2.csv / ps_new_yellow_ecoflex_random_2.csv ---\n",
            "FT Change: 2.3585 s, PSOC Change: 2.9332 s\n",
            "Alignment complete: 22323 samples. Avg time diff: 4.154 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Eco_ALIGNED\\ft_ALIGNED_new_yellow_ecoflex_random_2.csv\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: Poly/\n",
            "Saving to OUTPUT: Poly_ALIGNED/\n",
            "==================================================================\n",
            "\n",
            "--- Processing Pair: ft_new_yellow_poly_1.csv / ps_new_yellow_poly_1.csv ---\n",
            "FT Change: 1.5855 s, PSOC Change: 2.2660 s\n",
            "Alignment complete: 22316 samples. Avg time diff: 4.795 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Poly_ALIGNED\\ft_ALIGNED_new_yellow_poly_1.csv\n",
            "\n",
            "--- Processing Pair: ft_new_yellow_poly_random.csv / ps_new_yellow_poly_random.csv ---\n",
            "FT Change: 0.4800 s, PSOC Change: 2.0041 s\n",
            "Alignment complete: 22317 samples. Avg time diff: 15.254 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Poly_ALIGNED\\ft_ALIGNED_new_yellow_poly_random.csv\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: Eco/\n",
            "Saving to OUTPUT: Eco_ALIGNED/\n",
            "==================================================================\n",
            "\n",
            "--- Processing Pair: ft_old_blue_ecoflex_1.csv / ps_old_blue_ecoflex_1.csv ---\n",
            "FT Change: 3.8318 s, PSOC Change: 3.8681 s\n",
            "Alignment complete: 22320 samples. Avg time diff: 1.836 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Eco_ALIGNED\\ft_ALIGNED_old_blue_ecoflex_1.csv\n",
            "\n",
            "--- Processing Pair: ft_old_blue_ecoflex_random.csv / ps_old_blue_ecoflex_random.csv ---\n",
            "FT Change: 4.4349 s, PSOC Change: 3.8585 s\n",
            "Alignment complete: 22325 samples. Avg time diff: 2.258 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Eco_ALIGNED\\ft_ALIGNED_old_blue_ecoflex_random.csv\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: Eco10/\n",
            "Saving to OUTPUT: Eco10_ALIGNED/\n",
            "==================================================================\n",
            "\n",
            "--- Processing Pair: ft_old_blue_ecoflex10_1.csv / ps_old_blue_ecoflex10_1.csv ---\n",
            "FT Change: 1.5095 s, PSOC Change: 2.2158 s\n",
            "Alignment complete: 22307 samples. Avg time diff: 5.080 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Eco10_ALIGNED\\ft_ALIGNED_old_blue_ecoflex10_1.csv\n",
            "\n",
            "--- Processing Pair: ft_old_blue_ecoflex10_random.csv / ps_old_blue_ecoflex10_random.csv ---\n",
            "FT Change: 0.7325 s, PSOC Change: 2.0319 s\n",
            "Alignment complete: 22338 samples. Avg time diff: 11.431 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Eco10_ALIGNED\\ft_ALIGNED_old_blue_ecoflex10_random.csv\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: Poly/\n",
            "Saving to OUTPUT: Poly_ALIGNED/\n",
            "==================================================================\n",
            "\n",
            "--- Processing Pair: ft_old_blue_poly_1.csv / ps_old_blue_poly_1.csv ---\n",
            "FT Change: 2.0127 s, PSOC Change: 2.8621 s\n",
            "Alignment complete: 22333 samples. Avg time diff: 7.577 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Poly_ALIGNED\\ft_ALIGNED_old_blue_poly_1.csv\n",
            "\n",
            "--- Processing Pair: ft_old_blue_poly_random.csv / ps_old_blue_poly_random.csv ---\n",
            "FT Change: 0.4199 s, PSOC Change: 2.0221 s\n",
            "Alignment complete: 22334 samples. Avg time diff: 16.560 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Poly_ALIGNED\\ft_ALIGNED_old_blue_poly_random.csv\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: Eco/\n",
            "Saving to OUTPUT: Eco_ALIGNED/\n",
            "==================================================================\n",
            "\n",
            "--- Processing Pair: ft_old_red_ecoflex_1.csv / ps_old_red_ecoflex_1.csv ---\n",
            "FT Change: 2.0508 s, PSOC Change: 4.1856 s\n",
            "Alignment complete: 22302 samples. Avg time diff: 27.418 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Eco_ALIGNED\\ft_ALIGNED_old_red_ecoflex_1.csv\n",
            "\n",
            "--- Processing Pair: ft_old_red_ecoflex_random.csv / ps_old_red_ecoflex_random.csv ---\n",
            "FT Change: 1.0223 s, PSOC Change: 1.9372 s\n",
            "Alignment complete: 22305 samples. Avg time diff: 6.798 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Eco_ALIGNED\\ft_ALIGNED_old_red_ecoflex_random.csv\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: Poly/\n",
            "Saving to OUTPUT: Poly_ALIGNED/\n",
            "==================================================================\n",
            "\n",
            "--- Processing Pair: ft_old_smallred_poly_1.csv / ps_old_smallred_poly_1.csv ---\n",
            "FT Change: 1.4075 s, PSOC Change: 3.4621 s\n",
            "Alignment complete: 22341 samples. Avg time diff: 25.579 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Poly_ALIGNED\\ft_ALIGNED_old_smallred_poly_1.csv\n",
            "\n",
            "--- Processing Pair: ft_old_smallred_poly_random.csv / ps_old_smallred_poly_random.csv ---\n",
            "FT Change: 1.0454 s, PSOC Change: 2.1219 s\n",
            "Alignment complete: 22342 samples. Avg time diff: 8.736 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Poly_ALIGNED\\ft_ALIGNED_old_smallred_poly_random.csv\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: Eco/\n",
            "Saving to OUTPUT: Eco_ALIGNED/\n",
            "==================================================================\n",
            "\n",
            "--- Processing Pair: ft_old_yellow_ecoflex_1.csv / ps_old_yellow_ecoflex_1.csv ---\n",
            "FT Change: 7.0849 s, PSOC Change: 7.4411 s\n",
            "Alignment complete: 22328 samples. Avg time diff: 2.895 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Eco_ALIGNED\\ft_ALIGNED_old_yellow_ecoflex_1.csv\n",
            "\n",
            "--- Processing Pair: ft_old_yellow_ecoflex_random.csv / ps_old_yellow_ecoflex_random.csv ---\n",
            "FT Change: 6.4611 s, PSOC Change: 5.0112 s\n",
            "Alignment complete: 22320 samples. Avg time diff: 2.235 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Eco_ALIGNED\\ft_ALIGNED_old_yellow_ecoflex_random.csv\n",
            "\n",
            "==================================================================\n",
            "Processing INPUT: Poly/\n",
            "Saving to OUTPUT: Poly_ALIGNED/\n",
            "==================================================================\n",
            "\n",
            "--- Processing Pair: ft_old_smallyellow_poly_1.csv / ps_old_smallyellow_poly_1.csv ---\n",
            "FT Change: 1.3702 s, PSOC Change: 6.4697 s\n",
            "Alignment complete: 22316 samples. Avg time diff: 146.123 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Poly_ALIGNED\\ft_ALIGNED_old_smallyellow_poly_1.csv\n",
            "\n",
            "--- Processing Pair: ft_old_smallyellow_poly_random.csv / ps_old_smallyellow_poly_random.csv ---\n",
            "FT Change: 1.5973 s, PSOC Change: 1.8661 s\n",
            "Alignment complete: 22322 samples. Avg time diff: 2.682 ms\n",
            "Data saved to: .\\Aligned_FT_Data\\Poly_ALIGNED\\ft_ALIGNED_old_smallyellow_poly_random.csv\n",
            "\n",
            "\n",
            "######################################################################\n",
            "## All Recursive Processing Complete \n",
            "######################################################################\n",
            "Successfully processed and saved 33 unique pairs across all subdirectories.\n"
          ]
        }
      ],
      "source": [
        "total_processed_pairs = 0\n",
        "processed_results = {}\n",
        "files_by_dir = defaultdict(list)\n",
        "\n",
        "print(\"\\n\" + \"#\"*70)\n",
        "print(\"## Starting Recursive Data Alignment with Dynamic Folders \")\n",
        "print(\"#\"*70)\n",
        "print(f\"Input Base (Current Directory): {os.path.abspath(data_folder_dp)}\")\n",
        "print(f\"Output Base: {os.path.abspath(output_base_dp)}\")\n",
        "\n",
        "\n",
        "# Step 1: Recursively find and group files by their subdirectories\n",
        "# Starts searching from the current directory (data_folder_dp = '.')\n",
        "for root, dirs, files in os.walk(data_folder_dp):\n",
        "    # Skip the root data folder ('.') and the 'All_Combined_Data' folder (if it exists)\n",
        "    if root == data_folder_dp or root == '.' or 'All_Combined_Data' in root:\n",
        "        continue\n",
        "    \n",
        "    csv_files = [f for f in files if f.endswith('.csv')]\n",
        "    \n",
        "    if csv_files:\n",
        "        # Store full paths of the CSV files\n",
        "        for f in csv_files:\n",
        "            files_by_dir[root].append(os.path.join(root, f))\n",
        "        \n",
        "        print(f\"Found {len(csv_files)} files in: {os.path.basename(root)}/\")\n",
        "\n",
        "\n",
        "# Step 2: Iterate through each directory and process the matched pairs\n",
        "for input_full_path, full_paths in files_by_dir.items():\n",
        "    \n",
        "    # 2a. Define the dynamic output folder\n",
        "    subfolder_name = os.path.basename(input_full_path)\n",
        "    output_subfolder_dp = os.path.join(output_base_dp, f\"{subfolder_name}_ALIGNED\")\n",
        "    os.makedirs(output_subfolder_dp, exist_ok=True)\n",
        "    \n",
        "    print(f\"\\n==================================================================\")\n",
        "    print(f\"Processing INPUT: {subfolder_name}/\")\n",
        "    print(f\"Saving to OUTPUT: {os.path.basename(output_subfolder_dp)}/\")\n",
        "    print(f\"==================================================================\")\n",
        "\n",
        "    # 2b. Check for matching pairs (we use only the base filenames for the pairing logic)\n",
        "    filenames = [os.path.basename(p) for p in full_paths]\n",
        "    matching_pairs, unmatched_files = check_and_group_file_pairs(filenames)\n",
        "    \n",
        "    if not matching_pairs:\n",
        "        print(f\"No matching FT/PS pairs found in {subfolder_name}. Skipping to next folder.\")\n",
        "        continue\n",
        "\n",
        "    # Map filenames back to their full paths for processing\n",
        "    path_map = {os.path.basename(p): p for p in full_paths}\n",
        "\n",
        "    # 2c. Process and synchronize each pair\n",
        "    for suffix, files in matching_pairs.items():\n",
        "        try:\n",
        "            ft_file_name = [f for f in files if f.lower().startswith('ft')][0]\n",
        "            psoc_file_name = [f for f in files if f.lower().startswith('ps')][0]\n",
        "            \n",
        "            ft_full_path = path_map[ft_file_name]\n",
        "            psoc_full_path = path_map[psoc_file_name]\n",
        "        except IndexError:\n",
        "            print(f\"Skipping pair with suffix '{suffix}': Filenames not found in path map.\")\n",
        "            continue\n",
        "        \n",
        "        # Call the processing function using full paths and the dynamic output folder\n",
        "        aligned_df, output_file = process_and_synchronize_pair_flexible(\n",
        "            ft_full_path, \n",
        "            psoc_full_path, \n",
        "            output_subfolder_dp # Use the new, specific subfolder path\n",
        "        )\n",
        "        \n",
        "        if aligned_df is not None:\n",
        "            unique_key = f\"{subfolder_name}_{suffix}\"\n",
        "            processed_results[unique_key] = {\n",
        "                'dataframe': aligned_df,\n",
        "                'path': output_file\n",
        "            }\n",
        "            total_processed_pairs += 1\n",
        "\n",
        "print(\"\\n\\n\" + \"#\"*70)\n",
        "print(\"## All Recursive Processing Complete \")\n",
        "print(\"#\"*70)\n",
        "print(f\"Successfully processed and saved {total_processed_pairs} unique pairs across all subdirectories.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "HB-8FPAkatTF"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
